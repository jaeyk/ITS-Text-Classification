---
title: "Text classification"
author: "Jae Yeon Kim"
date: "3/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages 

```{r}
if (!require(pacman)) install.packages("pacman")

p_load(here, # creating computationally reproducible file paths 
       glue, # gluing strings and objects 
       janitor, # data cleaning tool 
       patchwork, # arranging ggplots 
       tidyverse, # tidyverse framework 
       tidymodels, # ML framework 
       textrecipes, # preprocessing text data 
       parallel, # parallel processing 
       doParallel, # parallel processing
       doFuture, # parallel processing 
       vip, # variable importance plots
       purrr) # functional programming 

# Import R scripts

script_list <- list.files(paste0(here::here(), "/functions"),
  pattern = "*.r|*.R",
  full.names = TRUE
)

for (i in 1:length(script_list))
{
  source(script_list[[i]])
}
```

# Load data 

```{r}
# Drop the first column as it's meaningless 
articles <- read.csv(here("processed_data/cleaned_text.csv"))[,-c(1,7:9)] 

articles %>%
  janitor::tabyl(category)

```

# Preproceessing text 

```{r}
#Install spacyr and spacy 
#p_load(spacyr)
#spacyr::spacy_install()

rec_articles <- articles %>% 
  recipe(category ~ text + source + group + intervention) %>%
  # If character or factor variables are included, you should dummify them 
  step_dummy(c(source, group, intervention)) %>%
  # Tokenize (make sure you installed spacy in Python)
  step_tokenize(text, token = "ngrams", options = list(n = 2)) %>% # Removed stopwords 
  step_stopwords(text) %>%
  # Filtered tokens 
  step_tokenfilter(text, max_tokens = 1000) %>%
  # Normalize document length 
  step_tfidf(text) %>%
  # Normalize all predictors 
  step_normalize(all_predictors()) %>%
  prep()
```

# Split data 

```{r}
# for reproducibility 
set.seed(1234)
# split (stratified random sampling)
split_class <- initial_split(articles, strata = category, 
                             prop = 0.9)

# training set 
raw_train_class <- training(split_class)
raw_test_class <- testing(split_class)

# x features (predictors)
train_x_class <- bake(rec_articles, 
                      raw_train_class, all_predictors())
test_x_class <- bake(rec_articles, 
                     raw_test_class, all_predictors())

# y outcomes (outcomes)
train_y_class <- bake(rec_articles, 
                      raw_train_class, all_outcomes())$category %>% as.factor()
test_y_class <- bake(rec_articles, raw_test_class, all_outcomes())$category %>% as.factor()

```

# Model building 

```{r}
# Lasso spec 
lasso_spec <- logistic_reg(penalty = tune(), # tuning hyperparameter 
                         mixture = 1) %>% # 1 = lasso, 0 = ridge 
  set_engine("glmnet") %>%
  set_mode("classification") 
# Random forest spec
rand_spec <- 
  rand_forest(
           mode = "classification",
           
           # Tuning hyperparameters
           mtry = tune(), 
           min_n = tune()) %>%
  set_engine("ranger",
             seed = 1234, 
             importance = "permutation")
# XGBoost spec 
xg_spec <- boost_tree(
  
           # Mode 
           mode = "classification",
           
           # Tuning hyperparameters
           
           # The number of trees to fit, aka boosting iterations
           trees = tune(),
           # The depth of the decision tree (how many levels of splits).
           tree_depth = tune(), 
           # Learning rate: lower means the ensemble will adapt more slowly.
           learn_rate = tune(),
           # Stop splitting a tree if we only have this many obs in a tree node.
           min_n = tune(),
           loss_reduction = tune(),
           # The number of randomly selected hyperparameters 
           mtry = tune(), 
           # The size of the data set used for modeling within an iteration
           sample_size = tune()
          ) %>% 
  set_engine("xgboost")
```

# Model tuning 

## Setup 

```{r}
all_cores <- parallel::detectCores(logical = FALSE)
registerDoFuture()

cl <- makeCluster(all_cores[1] - 1)

registerDoParallel(cl)
```

```{r}
# penalty() searches 50 possible combinations 

lambda_grid <- grid_regular(penalty(), levels = 50)

rand_grid <- grid_regular(mtry(range = c(1, 10)),
                          min_n(range = c(2, 10)),
                          levels = 5)
  
xg_grid <- grid_latin_hypercube(
  trees(),
  tree_depth(),
  learn_rate(),
  min_n(),
  loss_reduction(), 
  sample_size = sample_prop(),
  finalize(mtry(), train_x_class),
  size = 30
  )

# 10-fold cross-validation

set.seed(1234) # for reproducibility 

rec_folds <- vfold_cv(train_x_class %>% bind_cols(tibble(category = train_y_class)),
                      strata = category)

save(lambda_grid, rand_grid, xg_grid, file = here("output/grids.RData"))
          
save(rec_folds, file = here("output", glue("folds.RData")))
```

## Add setup to workflow 

```{r}
# Lasso 
lasso_wf <- workflow() %>%
  add_model(lasso_spec) %>%
  add_formula(category ~ . )

# Random forest
rand_wf <- lasso_wf %>%
  update_model(rand_spec)

# XGBoost 
xg_wf <- lasso_wf %>%
  update_model(xg_spec)
```

## Tuning results 

```{r}
metrics <- yardstick::metric_set(accuracy, precision, recall, f_meas)

# Lasso
lasso_res <- lasso_wf %>%
  tune_grid(
    resamples = rec_folds, 
    grid = lambda_grid, 
    metrics = metrics 
  )

# Random forest
rand_res <- rand_wf %>%
  tune_grid(
    resamples = rec_folds, 
    grid = rand_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metrics
  )

# XGBoost 
xg_res <- xg_wf %>%
  tune_grid(
    resamples = rec_folds, 
    grid = xg_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metrics
  )

save(lasso_res, rand_res, xg_res, file = here("output/res.RData"))
```

## Selecting the best performing model 

```{r}
best_lasso <- select_best(lasso_res, metric = "accuracy")
best_rand <- select_best(rand_res, metric = "accuracy")
best_xg <- select_best(xg_res, metric = "accuracy")
```

## Finalizing the workflow

```{r}
# Lasso
lasso_wf <- lasso_wf %>% finalize_workflow(best_lasso) 

# Random forest 
rand_wf <- rand_wf %>% finalize_workflow(best_rand)

# XGBoost 
xg_wf <- xg_wf %>% finalize_workflow(best_xg)
```

## Fit models 

```{r}
# Lasso 
lasso_fit <- lasso_wf %>%
  fit(train_x_class %>% bind_cols(tibble(category = train_y_class)))

# Random forest 
rand_fit <- rand_wf %>%
  fit(train_x_class %>% bind_cols(tibble(category = train_y_class)))

# XGBoost 
xg_fit <- xg_wf %>%
  fit(train_x_class %>% bind_cols(tibble(category = train_y_class)))

save(lasso_fit, rand_fit, xg_fit, file = here("output/fits.RData"))

```

# Model evaluation 

This result is based on the test data. 

## Confusion matrix 

```{r}
(visualize_class_eval(lasso_fit) + labs(title = "Lasso")) /

(visualize_class_eval(rand_fit) + labs(title = "Random forest"))  /
(visualize_class_eval(xg_fit) + labs(title = "XGBoost"))

ggsave(here("output", "ml_eval.png"), height = 10)
```

## Variable importance 

```{r}
vi_plot_else(rand_fit, "Random forest") 

ggsave(here("output", "vip_eval.png"))
```

# Predict unseen data 

```{r}
# Munging data 
unlabeled_articles <- read.csv(here("raw_data/unlabeled_articles.csv"))[,-1]
  
unlabeled_articles$date <- lubridate::ymd(unlabeled_articles$date)

unlabeled_articles$group <- ifelse(unlabeled_articles$source == "The Arab American News", "Arab", "Indian")

# Preprocessing 
unlabeled_articles_preprocessed <- bake(rec_articles, unlabeled_articles)

# Prediction 
unlabeled_articles$category <- predict(rand_fit, unlabeled_articles_preprocessed)$.pred_class

write.csv(unlabeled_articles, here("processed_data/predicted.csv"))
```

# Turn an R markdown into an R script 

```{r eval = FALSE}
knitr::purl(input = here("code/05_02_classifying_text.Rmd"),
            output = here("code/05_02_classifying_text.r"))
```


