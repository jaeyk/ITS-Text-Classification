---
title: "Embedding regression"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages 

```{r}

# Import pkgs
pacman::p_load(
  tidyverse,
  lubridate, 
  purrr,
  furrr,
  tm,
  quanteda, 
  here,
  tidytext, # text analysis 
  textclean,
  textstem, 
  ggthemes,
  text2vec, # word embedding 
  widyr,
  patchwork, # arranging ggplots
  glue,
  # deep learning 
  text2vec,
  # network graph
  igraph,
  ggraph,
  # structural breakpoint
  strucchange,
  pbapply
)

devtools::install_github("prodriguezsosa/conText")

library(conText)

theme_set(theme_clean())

source(here("functions", "embedding.r"))
```

# Load data 

```{r}
# Drop the first column as it's meaningless 
corpus <- read.csv(here("processed_data/cleaned_text.csv"))[,-c(1,7:9)] 

# Create dummy variables 
corpus$intervention <- if_else(corpus$date >= as.Date("2001-09-11"), 1, 0)

corpus$group <- if_else(corpus$group == "Arab", 1, 0)
```

# Preproceessing text 

```{r eval = FALSE}
corpus$clean_text <- clean_text(corpus$text)

corpus$clean_text <- str_replace_all(corpus$clean_text, "muslims", "muslim")
```

# Local embedding and matrix 

```{r eval = FALSE}
set.seed(1234L)
local_glove <- df2vec(corpus)
local_transform <- df2ltm(corpus, local_glove)

save(local_glove, local_transform, 
     file = here("processed_data/context_bg.Rdata"))
```

## ALC embedding approach 

### Regression 

```{r eval = FALSE}
mod <- conText(formula = muslim ~ intervention + group, 
          data = corpus, 
          text_var = 'clean_text', 
          pre_trained = local_glove,
          transform = TRUE, 
          transform_matrix = local_transform, 
          bootstrap = TRUE, 
          num_bootstraps = 20, 
          stratify_by = c('intervention', 'group'),
          permute = TRUE, 
          num_permutations = 100, 
          window = 6, 
          valuetype = 'fixed', 
          case_insensitive = TRUE, 
          hard_cut = FALSE, 
          verbose = FALSE)

plot_tibble <- mod$normed_betas %>% 
  mutate(Coefficient = c("9/11 attacks", "Arab American")) %>% 
  mutate(Coefficient = factor(Coefficient, levels = Coefficient))

plot_tibble
```

```{r eval = FALSE}
reg_plot <- plot_tibble %>%
  ggplot(aes(x = Coefficient, y = Normed_Estimate)) + 
  geom_bar(position = position_dodge(), 
    stat = "identity", width = 0.5) + 
  geom_errorbar(aes(ymin = Normed_Estimate - 
    1.96 * Std.Error, ymax = Normed_Estimate + 1.96 * Std.Error), size = 0.75, width = 0.15, 
    position = position_dodge(0.9)) + 
  ylab("Norm of beta hats") + 
  theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.5, hjust = 1),
          axis.text.y = element_text(size = 10)) +
  labs(title = "Keyword: Muslim")

reg_plot

ggsave(here("output", "embedreg.png"))
```

# Nearest neighbors 

## ALC embedding 

```{r eval = FALSE}
set.seed(1234L)
arab_post_bt <- get_bt_terms(1, 1, "muslim", 150)
indian_post_bt <- get_bt_terms(1, 0, "muslim", 150)

arab_pre_bt <- get_bt_terms(0, 1, "muslim", 150)
indian_pre_bt <- get_bt_terms(0, 0, "muslim", 150)
```

```{r eval = FALSE}
terms2plot_sep(arab_pre_bt, indian_pre_bt, "Muslim", "Pre-9/11") + terms2plot_sep(arab_post_bt, indian_post_bt, "Muslim", "Post-9/11")

ggsave(here("output", "btmuslimsep.png"), width = 12, height = 10)
```

# Reading documents

```{r eval = FALSE}
corpus %>%
  # Post 9/11
  filter(intervention == 1) %>%
  # Arab newspaper 
  filter(group == 1) %>%
  # Search documents including the term "immigrant"
  filter(str_detect(text, "immigrant|Immigrant|immigrants|Immigrants")) %>%
  # Select the 3rd row (the 3rd document)
  slice(3) %>%
  # Pull the text 
  pull(text)

corpus %>%
  # Post 9/11
  filter(intervention == 1) %>%
  # Arab newspaper 
  filter(group == 1) %>%
  # Search documents including the term "immigrant"
  filter(str_detect(text, "immigrant|Immigrant|immigrants|Immigrants")) %>%
  # Select the 3rd row (the 3rd document)
  slice(3) %>%
  # Pull the date and newspaper
  pull(date, source)
```