{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification \n",
    "\n",
    "[Carlos Ortiz](https://www.linkedin.com/in/carlosortizdev/), [Sarah Santiago](https://www.linkedin.com/in/sarah-santiago-7a297b18a/), and [Vivek Datta](https://www.linkedin.com/in/vivek-datta/) did initial coding. Jae Yeon Kim reviewed and modified the code. Please use the `Python2` kernel to run this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include relevant imports here\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Data manipulation \n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, cohen_kappa_score, precision_score, recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in scraped articles from csv file to dataframe\n",
    "articles = pd.read_csv('/home/jae/ITS-Text-Classification/processed_data/cleaned_text.csv')\n",
    "\n",
    "placebo_articles = pd.read_csv('/home/jae/ITS-Text-Classification/processed_data/placebo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conduct train-test split where 90% of data used for training\n",
    "\n",
    "train, val = train_test_split(articles, \n",
    "                              test_size = 0.1,\n",
    "                              random_state = 42) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all of the words that are in NA vs not in NA\n",
    "\n",
    "NA_count = Counter(\" \".join(train[train['category'] == 0]['text']).split())\n",
    "\n",
    "not_NA_count = Counter(\" \".join(train[train['category'] == 1]['text']).split())\n",
    "\n",
    "# Creating dataframe named testing to hold these counts\n",
    "\n",
    "testing = pd.DataFrame({\"NA\": NA_count, \"Not NA\": not_NA_count}).fillna(0)\n",
    "\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column of times NA appeared more than not NA\n",
    "testing['NA distinct'] = testing['NA'] - testing['Not NA']\n",
    "testing = testing.sort_values(by = 'NA distinct', ascending = False)\n",
    "\n",
    "# Make column of percentage of words\n",
    "testing['NA percent'] = testing['NA'] / (testing['NA'] +  testing['Not NA'])\n",
    "tester = testing[testing['Not NA'] > 0].sort_values(by = 'NA percent', ascending = False)\n",
    "\n",
    "# Above work leads to creating of the top 100 words that appear in NA articles, as seen in words areray\n",
    "words = tester[tester['NA'] > 100].sort_values(by = 'NA distinct', ascending = False).head(300).reset_index()['index'].values.astype(str)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create counts of how often the number of times top 100 words appeared in all articles, with 1 and 2 grams\n",
    "cv = CountVectorizer(vocabulary=words, ngram_range = (1, 2))\n",
    "\n",
    "# Encode the count vectorizer to create a dataframe holding counts\n",
    "ohc_words_x_train = pd.DataFrame(cv.fit_transform(train['text']))\n",
    "\n",
    "ohc_words_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get addition features from one hot encoding the source, intervention, and group columns\n",
    "features_x_train = pd.concat([pd.get_dummies(train[col]) for col in ['source', 'intervention', 'group']], axis=1)\n",
    "features_x_train = features_x_train.drop(columns = [\"The Arab American View\"])\n",
    "features_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final training matrix from the above two dataframes created from cells\n",
    "xx_train = pd.merge(left=ohc_words_x_train, left_index=True\n",
    "                    ,right=features_x_train, right_index=True,\n",
    "                    how='inner')\n",
    "xx_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing lasso (least absolute shrinkage and selection operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit our Logistic Regression model with L1 regularization and determine the training accuracy\n",
    "\n",
    "yy_train = train['category']\n",
    "\n",
    "NA_model = LogisticRegressionCV(fit_intercept = True, \n",
    "                                penalty = 'l1', \n",
    "                                solver = 'saga')\n",
    "\n",
    "NA_model.fit(xx_train, yy_train)\n",
    "\n",
    "accuracy = NA_model.score(xx_train, yy_train)\n",
    "\n",
    "print(\"Training Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above process for word count matrix in testing\n",
    "cv = CountVectorizer(vocabulary=words, \n",
    "                     ngram_range = (1, 2))\n",
    "\n",
    "ohc_words_x_test = pd.SparseDataFrame(cv.fit_transform(val['text']), \n",
    "                       val.index,\n",
    "                       cv.get_feature_names(), \n",
    "                       default_fill_value=0)\n",
    "\n",
    "ohc_words_x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Repeat the above process for feature matrix in testing \n",
    "\n",
    "features_x_test = pd.concat([pd.get_dummies(val[col]) for col in ['source', 'intervention', 'group']], axis=1)\n",
    "\n",
    "features_x_test = features_x_test.drop(columns = [\"The Arab American View\"])\n",
    "\n",
    "features_x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merging above dataframes to get the final testing matrix \n",
    "\n",
    "xx_test = pd.merge(left=ohc_words_x_test, left_index=True\n",
    "                  ,right=features_x_test, right_index=True,\n",
    "                   how='inner')\n",
    "\n",
    "xx_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    return(accuracy, precision, recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_model(NA_model, x_test = xx_test, y_test = val['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(test_results, columns = ['Scores'])\n",
    "\n",
    "table['Metrics'] = ['Accuracy', 'Precision', 'Recall']\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Label the unlabeled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the unlabeled data and follow procedures in the beginning of notebook to clean\n",
    "\n",
    "unlabeled_articles = pd.read_csv('/home/jae/ITS-Text-Classification/raw_data/unlabeled_articles.csv', index_col=0)\n",
    "\n",
    "unlabeled_articles['date'] =  pd.to_datetime(unlabeled_articles['date'], format='%Y%m%d')\n",
    "\n",
    "unlabeled_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize whether article pertains to Arab-American or Indian-American issues based on publication source\n",
    "\n",
    "response = []\n",
    "\n",
    "for x in unlabeled_articles['source']:\n",
    "    if x == \"The Arab American News\":\n",
    "        response.append(\"Arab\")\n",
    "    else:\n",
    "        response.append(\"Indian\")\n",
    "\n",
    "unlabeled_articles['group'] = response\n",
    "\n",
    "unlabeled_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count encoding dataframe of top words again, except for unlabeled data\n",
    "cv = CountVectorizer(vocabulary=words, ngram_range = (1, 2))\n",
    "\n",
    "ohc_words_x_unlabeled = pd.SparseDataFrame(cv.fit_transform(unlabeled_articles['text']), \n",
    "                       unlabeled_articles.index,\n",
    "                       cv.get_feature_names(), \n",
    "                       default_fill_value=0)\n",
    "\n",
    "ohc_words_x_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, except with the source, intervetion, and group features\n",
    "features_x_unlabeled = pd.get_dummies(unlabeled_articles, columns=['source', 'intervention', 'group'])\n",
    "features_x_unlabeled = features_x_unlabeled.drop(columns = ['text', 'date'])\n",
    "features_x_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data matrix created here\n",
    "xx_unlabeled = pd.merge(left=ohc_words_x_unlabeled, left_index=True\n",
    "                  ,right=features_x_unlabeled, right_index=True,\n",
    "                  how='inner')\n",
    "\n",
    "xx_unlabeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model to predict whether the articles pertained to domestic vs non-domestic isues\n",
    "values = NA_model.predict(xx_unlabeled)\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Label the unlabeled placebo data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc_words_placebo = pd.SparseDataFrame(cv.fit_transform(placebo_articles['text']), \n",
    "                       index = placebo_articles.index,\n",
    "                       columns = cv.get_feature_names(), \n",
    "                       default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the column names that only existed in the left dataframe \n",
    "lost_cols = list(set(xx_unlabeled.columns).difference(ohc_words_placebo.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop\n",
    "for i in range(len(lost_cols)):\n",
    "    \n",
    "    ohc_words_placebo[lost_cols[i]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "set(xx_unlabeled.columns).difference(ohc_words_placebo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict \n",
    "placebo_values= NA_model.predict(ohc_words_placebo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results into a csv file\n",
    "# pd.DataFrame(values, xx_unlabeled.index).to_csv(\"/home/jae/ITS-Text-Classification/processed_data/predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results into a csv file \n",
    "\n",
    "pd.DataFrame(placebo_values).to_csv(\"/home/jae/ITS-Text-Classification/processed_data/placebo_predicted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
